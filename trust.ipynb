{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: tabulate in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (0.8.9)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymupdf\n",
    "\n",
    "# !pip install pymupdf4llm\n",
    "\n",
    "# !pip install pdfplumber\n",
    "# !pip install pandas\n",
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.11.14-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.14 (from llama-index)\n",
      "  Downloading llama_index_core-0.11.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.9 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl.metadata (648 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.35-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading aiohttp-3.10.8-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting numpy<2.0.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading pillow-10.4.0-cp39-cp39-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading tiktoken-0.7.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.0-py3-none-any.whl.metadata (750 bytes)\n",
      "Collecting pandas (from llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
      "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting click (from nltk>3.8.1->llama-index)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index)\n",
      "  Downloading regex-2024.9.11-cp39-cp39-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading yarl-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (50 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting anyio (from httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio (from httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading jiter-0.5.0-cp39-cp39-macosx_10_12_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading pydantic_core-2.23.4-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio->httpx->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting packaging>=17.0 (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.14->llama-index)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading llama_index-0.11.14-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.11.14-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.2.9-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.8-cp39-cp39-macosx_10_9_x86_64.whl (400 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading llama_cloud-0.1.0-py3-none-any.whl (176 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading llama_parse-0.5.6-py3-none-any.whl (10 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
      "Downloading pillow-10.4.0-cp39-cp39-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp39-cp39-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl (184 kB)\n",
      "Downloading regex-2024.9.11-cp39-cp39-macosx_10_9_x86_64.whl (287 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp39-cp39-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.7.0-cp39-cp39-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.8/961.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl (37 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading pandas-2.2.3-cp39-cp39-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl (122 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl (55 kB)\n",
      "Downloading greenlet-3.1.1-cp39-cp39-macosx_11_0_universal2.whl (270 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.5.0-cp39-cp39-macosx_10_12_x86_64.whl (284 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl (117 kB)\n",
      "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, regex, PyYAML, pillow, packaging, numpy, networkx, nest-asyncio, mypy-extensions, joblib, jiter, idna, h11, greenlet, fsspec, frozenlist, exceptiongroup, distro, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, typing-inspect, SQLAlchemy, requests, python-dateutil, pypdf, pydantic-core, nltk, multidict, marshmallow, httpcore, deprecated, beautifulsoup4, anyio, aiosignal, yarl, tiktoken, pydantic, pandas, httpx, dataclasses-json, openai, llama-cloud, aiohttp, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: striprtf\n",
      "    Found existing installation: striprtf 0.0.26\n",
      "    Uninstalling striprtf-0.0.26:\n",
      "      Successfully uninstalled striprtf-0.0.26\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.2\n",
      "    Uninstalling pytz-2024.2:\n",
      "      Successfully uninstalled pytz-2024.2\n",
      "  Attempting uninstall: dirtyjson\n",
      "    Found existing installation: dirtyjson 1.0.8\n",
      "    Uninstalling dirtyjson-1.0.8:\n",
      "      Successfully uninstalled dirtyjson-1.0.8\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.2\n",
      "    Uninstalling tzdata-2024.2:\n",
      "      Successfully uninstalled tzdata-2024.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.5\n",
      "    Uninstalling tqdm-4.66.5:\n",
      "      Successfully uninstalled tqdm-4.66.5\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.5.0\n",
      "    Uninstalling tenacity-8.5.0:\n",
      "      Successfully uninstalled tenacity-8.5.0\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.6\n",
      "    Uninstalling soupsieve-2.6:\n",
      "      Successfully uninstalled soupsieve-2.6\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.1\n",
      "    Uninstalling sniffio-1.3.1:\n",
      "      Successfully uninstalled sniffio-1.3.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.9.11\n",
      "    Uninstalling regex-2024.9.11:\n",
      "      Successfully uninstalled regex-2024.9.11\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.4.0\n",
      "    Uninstalling pillow-10.4.0:\n",
      "      Successfully uninstalled pillow-10.4.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 1.0.0\n",
      "    Uninstalling mypy-extensions-1.0.0:\n",
      "      Successfully uninstalled mypy-extensions-1.0.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: jiter\n",
      "    Found existing installation: jiter 0.5.0\n",
      "    Uninstalling jiter-0.5.0:\n",
      "      Successfully uninstalled jiter-0.5.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.1.1\n",
      "    Uninstalling greenlet-3.1.1:\n",
      "      Successfully uninstalled greenlet-3.1.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.1\n",
      "    Uninstalling frozenlist-1.4.1:\n",
      "      Successfully uninstalled frozenlist-1.4.1\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.2.2\n",
      "    Uninstalling exceptiongroup-1.2.2:\n",
      "      Successfully uninstalled exceptiongroup-1.2.2\n",
      "  Attempting uninstall: distro\n",
      "    Found existing installation: distro 1.9.0\n",
      "    Uninstalling distro-1.9.0:\n",
      "      Successfully uninstalled distro-1.9.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.8.30\n",
      "    Uninstalling certifi-2024.8.30:\n",
      "      Successfully uninstalled certifi-2024.8.30\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 24.2.0\n",
      "    Uninstalling attrs-24.2.0:\n",
      "      Successfully uninstalled attrs-24.2.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 4.0.3\n",
      "    Uninstalling async-timeout-4.0.3:\n",
      "      Successfully uninstalled async-timeout-4.0.3\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.4.3\n",
      "    Uninstalling aiohappyeyeballs-2.4.3:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.4.3\n",
      "  Attempting uninstall: typing-inspect\n",
      "    Found existing installation: typing-inspect 0.9.0\n",
      "    Uninstalling typing-inspect-0.9.0:\n",
      "      Successfully uninstalled typing-inspect-0.9.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.35\n",
      "    Uninstalling SQLAlchemy-2.0.35:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.35\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.3.1\n",
      "    Uninstalling pypdf-4.3.1:\n",
      "      Successfully uninstalled pypdf-4.3.1\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.23.4\n",
      "    Uninstalling pydantic_core-2.23.4:\n",
      "      Successfully uninstalled pydantic_core-2.23.4\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.9.1\n",
      "    Uninstalling nltk-3.9.1:\n",
      "      Successfully uninstalled nltk-3.9.1\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.1.0\n",
      "    Uninstalling multidict-6.1.0:\n",
      "      Successfully uninstalled multidict-6.1.0\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.22.0\n",
      "    Uninstalling marshmallow-3.22.0:\n",
      "      Successfully uninstalled marshmallow-3.22.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.6\n",
      "    Uninstalling httpcore-1.0.6:\n",
      "      Successfully uninstalled httpcore-1.0.6\n",
      "  Attempting uninstall: deprecated\n",
      "    Found existing installation: Deprecated 1.2.14\n",
      "    Uninstalling Deprecated-1.2.14:\n",
      "      Successfully uninstalled Deprecated-1.2.14\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.3\n",
      "    Uninstalling beautifulsoup4-4.12.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.6.0\n",
      "    Uninstalling anyio-4.6.0:\n",
      "      Successfully uninstalled anyio-4.6.0\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.13.1\n",
      "    Uninstalling yarl-1.13.1:\n",
      "      Successfully uninstalled yarl-1.13.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.2\n",
      "    Uninstalling pydantic-2.9.2:\n",
      "      Successfully uninstalled pydantic-2.9.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.2\n",
      "    Uninstalling httpx-0.27.2:\n",
      "      Successfully uninstalled httpx-0.27.2\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.6.7\n",
      "    Uninstalling dataclasses-json-0.6.7:\n",
      "      Successfully uninstalled dataclasses-json-0.6.7\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.51.0\n",
      "    Uninstalling openai-1.51.0:\n",
      "      Successfully uninstalled openai-1.51.0\n",
      "  Attempting uninstall: llama-cloud\n",
      "    Found existing installation: llama-cloud 0.1.0\n",
      "    Uninstalling llama-cloud-0.1.0:\n",
      "      Successfully uninstalled llama-cloud-0.1.0\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.10.8\n",
      "    Uninstalling aiohttp-3.10.8:\n",
      "      Successfully uninstalled aiohttp-3.10.8\n",
      "  Attempting uninstall: llama-index-legacy\n",
      "    Found existing installation: llama-index-legacy 0.9.48.post3\n",
      "    Uninstalling llama-index-legacy-0.9.48.post3:\n",
      "      Successfully uninstalled llama-index-legacy-0.9.48.post3\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.14\n",
      "    Uninstalling llama-index-core-0.11.14:\n",
      "      Successfully uninstalled llama-index-core-0.11.14\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.5.6\n",
      "    Uninstalling llama-parse-0.5.6:\n",
      "      Successfully uninstalled llama-parse-0.5.6\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.2.2\n",
      "    Uninstalling llama-index-readers-file-0.2.2:\n",
      "      Successfully uninstalled llama-index-readers-file-0.2.2\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.2.9\n",
      "    Uninstalling llama-index-llms-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.2.9\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.4.0\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.4.0:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.4.0\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.2.5\n",
      "    Uninstalling llama-index-embeddings-openai-0.2.5:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.2.5\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.3.0\n",
      "    Uninstalling llama-index-readers-llama-parse-0.3.0:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.3.0\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.2.1\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.2.1:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.2.1\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.3.1\n",
      "    Uninstalling llama-index-cli-0.3.1:\n",
      "      Successfully uninstalled llama-index-cli-0.3.1\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.3.4\n",
      "    Uninstalling llama-index-agent-openai-0.3.4:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.3.4\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.2.0\n",
      "    Uninstalling llama-index-program-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-program-openai-0.2.0\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.2.0\n",
      "    Uninstalling llama-index-question-gen-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.2.0\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.11.14\n",
      "    Uninstalling llama-index-0.11.14:\n",
      "      Successfully uninstalled llama-index-0.11.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "astroid 2.6.6 requires wrapt<1.13,>=1.11, but you have wrapt 1.16.0 which is incompatible.\n",
      "botocore 1.24.32 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\n",
      "jupyter-server 1.13.5 requires anyio<4,>=3.1.0, but you have anyio 4.6.0 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.0 async-timeout-4.0.3 attrs-24.2.0 beautifulsoup4-4.12.3 certifi-2024.8.30 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 exceptiongroup-1.2.2 frozenlist-1.4.1 fsspec-2024.9.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 idna-3.10 jiter-0.5.0 joblib-1.4.2 llama-cloud-0.1.0 llama-index-0.11.14 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.14 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.9 llama-index-multi-modal-llms-openai-0.2.1 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.6 marshmallow-3.22.0 multidict-6.1.0 mypy-extensions-1.0.0 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.9.1 numpy-1.26.4 openai-1.51.0 packaging-24.1 pandas-2.2.3 pillow-10.4.0 pydantic-2.9.2 pydantic-core-2.23.4 pypdf-4.3.1 python-dateutil-2.9.0.post0 pytz-2024.2 regex-2024.9.11 requests-2.32.3 six-1.16.0 sniffio-1.3.1 soupsieve-2.6 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 tqdm-4.66.5 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2024.2 urllib3-2.2.3 wrapt-1.16.0 yarl-1.13.1\n",
      "Requirement already satisfied: llama-parse in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (0.5.6)\n",
      "Requirement already satisfied: llama-index-core>=0.11.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-parse) (0.11.14)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (2024.9.0)\n",
      "Requirement already satisfied: httpx in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from llama-index-core>=0.11.0->llama-parse) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (4.0.3)\n",
      "Requirement already satisfied: click in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core>=0.11.0->llama-parse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core>=0.11.0->llama-parse) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-parse) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-parse) (3.22.0)\n",
      "Requirement already satisfied: anyio in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core>=0.11.0->llama-parse) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-parse) (24.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/choihyelynn/opt/anaconda3/lib/python3.9/site-packages (from anyio->httpx->llama-index-core>=0.11.0->llama-parse) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U llama-index --upgrade --no-cache-dir --force-reinstall\n",
    "!pip install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "# doc = fitz.open('/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/아이엠뱅크 신탁/(고객용) 상세상품설명서 20241025(비케이씨에스제오차).pdf')\n",
    "doc = fitz.open('/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/가계대출상품설명서_23.01.16.pdf')\n",
    "\n",
    "for page in doc:\n",
    "    text = page.get_text('text')  # Retains layout\n",
    "    print(text)\n",
    "\n",
    "# blocks = page.get_text('blocks')\n",
    "# for b in blocks:\n",
    "#     print(b[4])  # Print the text content of each block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PyMuPDF4LLM\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "input_directory = \"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/trust_pdfs/\"\n",
    "output_directory = \"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/trust_markdowns/\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Command to run in the terminal\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".pdf\"):  # Process only PDF files\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Command to run markdowntext.py with the file as input\n",
    "        command = ['python', 'markdowntext.py', file_path, output_directory]\n",
    "        \n",
    "        # Execute the command\n",
    "        subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open('/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/가계대출상품설명서_23.01.16.pdf') as f:\n",
    "    for page in f.pages:\n",
    "        print(page.extract_text())\n",
    "        print(page.extract_tables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/example/가계대출상품설명서_23.01.16.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# file = r\"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/아이엠뱅크 신탁/(고객용) 상세상품설명서 20241025(비케이씨에스제오차).pdf\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(extracted_text)\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mprocess_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#iterate over each table found on the page\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m page\u001b[38;5;241m.\u001b[39mfind_tables():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# print(page.crop(table.bbox).chars)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# print(page.crop(table.bbox).chars[0])\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     first_table_char \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchars\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m#stores the first character of the cropped table area\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     filtered_page \u001b[38;5;241m=\u001b[39m filtered_page\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m obj: \n\u001b[1;32m     23\u001b[0m         get_bbox_overlap(obj_to_bbox(obj), table\u001b[38;5;241m.\u001b[39mbbox) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     )  \u001b[38;5;66;03m# updated by filtering out characters that overlap with the table's bounding box\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     chars \u001b[38;5;241m=\u001b[39m filtered_page\u001b[38;5;241m.\u001b[39mchars\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pdfplumber.utils import extract_text, get_bbox_overlap, obj_to_bbox\n",
    "import tabulate\n",
    "import os\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    all_text = []\n",
    "\n",
    "    #iterate over each page\n",
    "    for page in pdf.pages:\n",
    "        filtered_page = page  #current page\n",
    "        chars = filtered_page.chars  #captures all characters on the filtered_page\n",
    "    \n",
    "        #iterate over each table found on the page\n",
    "        for table in page.find_tables():\n",
    "\n",
    "            first_table_char = page.crop(table.bbox).chars[0]  #stores the first character of the cropped table area\n",
    "            filtered_page = filtered_page.filter(lambda obj: \n",
    "                get_bbox_overlap(obj_to_bbox(obj), table.bbox) is None\n",
    "            )  # updated by filtering out characters that overlap with the table's bounding box\n",
    "            chars = filtered_page.chars\n",
    "\n",
    "            #create a DataFrame from the extracted table data\n",
    "            df = pd.DataFrame(table.extract())\n",
    "            df.columns = df.iloc[0]  #first row set as the header\n",
    "            markdown = df.drop(0).to_markdown(index=False)  # rest converted to Markdown format\n",
    "            chars.append(first_table_char  | {\"text\": markdown})  #first_table_char is updated with the markdown content and appended to chars\n",
    "        \n",
    "        page_text = extract_text(chars, layout = True) #extracts the text from the filtered characters with layout preservation\n",
    "        all_text.append(page_text)\n",
    "    \n",
    "    pdf.close()\n",
    "    return \"\\n\".join(all_text)\n",
    "\n",
    "file = r\"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/example/가계대출상품설명서_23.01.16.pdf\"\n",
    "# file = r\"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/아이엠뱅크 신탁/(고객용) 상세상품설명서 20241025(비케이씨에스제오차).pdf\"\n",
    "extracted_text = process_pdf(file)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdfplumber\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/trust_pdfs/(고객용) 상세상품설명서 20241025(비케이씨에스제오차).pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# first_page = pdf.pages[0]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# print(first_page.chars[0])\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# page_img = pdf_pages[0].to_image().original\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     im\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pdfplumber/page.py:606\u001b[0m, in \u001b[0;36mPage.to_image\u001b[0;34m(self, resolution, width, height, antialias, force_mediabox)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_image\u001b[39m(\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    594\u001b[0m     resolution: Optional[Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     force_mediabox: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPageImage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    You can pass a maximum of 1 of the following:\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    - resolution: The desired number pixels per inch. Defaults to 72.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    - width: The desired image width in pixels.\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    - height: The desired image width in pixels.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_RESOLUTION, PageImage\n\u001b[1;32m    608\u001b[0m     num_specs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [resolution, width, height])\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_specs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pdfplumber/display.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BufferedReader, BytesIO\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, List, Optional, Tuple, Union\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageDraw\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpypdfium2\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py:68\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_binary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m i32le, o32be, o32le\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecate\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOrBytesPath, TypeGuard\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeferredError, is_path\n\u001b[1;32m     71\u001b[0m ElementTree: ModuleType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/_typing.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Protocol, Sequence, TypeVar, Union\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnpt\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     NumpyArray \u001b[38;5;241m=\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[Any]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/typing/__init__.py:158\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m============================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTyping (:mod:`numpy.typing`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# NOTE: The API section will be appended with additional entries\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# further down in this file\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    159\u001b[0m     ArrayLike,\n\u001b[1;32m    160\u001b[0m     DTypeLike,\n\u001b[1;32m    161\u001b[0m     NBitBase,\n\u001b[1;32m    162\u001b[0m     NDArray,\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    165\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrayLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTypeLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBitBase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDArray\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/_typing/__init__.py:151\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nbit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     96\u001b[0m     _NBitByte \u001b[38;5;28;01mas\u001b[39;00m _NBitByte,\n\u001b[1;32m     97\u001b[0m     _NBitShort \u001b[38;5;28;01mas\u001b[39;00m _NBitShort,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     _NBitLongDouble \u001b[38;5;28;01mas\u001b[39;00m _NBitLongDouble,\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_char_codes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    109\u001b[0m     _BoolCodes \u001b[38;5;28;01mas\u001b[39;00m _BoolCodes,\n\u001b[1;32m    110\u001b[0m     _UInt8Codes \u001b[38;5;28;01mas\u001b[39;00m _UInt8Codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     _ObjectCodes \u001b[38;5;28;01mas\u001b[39;00m _ObjectCodes,\n\u001b[1;32m    150\u001b[0m )\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scalars\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    152\u001b[0m     _CharLike_co \u001b[38;5;28;01mas\u001b[39;00m _CharLike_co,\n\u001b[1;32m    153\u001b[0m     _BoolLike_co \u001b[38;5;28;01mas\u001b[39;00m _BoolLike_co,\n\u001b[1;32m    154\u001b[0m     _UIntLike_co \u001b[38;5;28;01mas\u001b[39;00m _UIntLike_co,\n\u001b[1;32m    155\u001b[0m     _IntLike_co \u001b[38;5;28;01mas\u001b[39;00m _IntLike_co,\n\u001b[1;32m    156\u001b[0m     _FloatLike_co \u001b[38;5;28;01mas\u001b[39;00m _FloatLike_co,\n\u001b[1;32m    157\u001b[0m     _ComplexLike_co \u001b[38;5;28;01mas\u001b[39;00m _ComplexLike_co,\n\u001b[1;32m    158\u001b[0m     _TD64Like_co \u001b[38;5;28;01mas\u001b[39;00m _TD64Like_co,\n\u001b[1;32m    159\u001b[0m     _NumberLike_co \u001b[38;5;28;01mas\u001b[39;00m _NumberLike_co,\n\u001b[1;32m    160\u001b[0m     _ScalarLike_co \u001b[38;5;28;01mas\u001b[39;00m _ScalarLike_co,\n\u001b[1;32m    161\u001b[0m     _VoidLike_co \u001b[38;5;28;01mas\u001b[39;00m _VoidLike_co,\n\u001b[1;32m    162\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    164\u001b[0m     _Shape \u001b[38;5;28;01mas\u001b[39;00m _Shape,\n\u001b[1;32m    165\u001b[0m     _ShapeLike \u001b[38;5;28;01mas\u001b[39;00m _ShapeLike,\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dtype_like\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    168\u001b[0m     DTypeLike \u001b[38;5;28;01mas\u001b[39;00m DTypeLike,\n\u001b[1;32m    169\u001b[0m     _DTypeLike \u001b[38;5;28;01mas\u001b[39;00m _DTypeLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     _DTypeLikeComplex_co \u001b[38;5;28;01mas\u001b[39;00m _DTypeLikeComplex_co,\n\u001b[1;32m    184\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/_typing/_scalars.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# The 6 `<X>Like_co` type-aliases below represent all scalars that can be\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# coerced into `<X>` (with the casting rule `same_kind`)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m _BoolLike_co \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mbool\u001b[39m, np\u001b[38;5;241m.\u001b[39mbool]\n\u001b[0;32m---> 13\u001b[0m _UIntLike_co \u001b[38;5;241m=\u001b[39m Union[_BoolLike_co, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsignedinteger\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     14\u001b[0m _IntLike_co \u001b[38;5;241m=\u001b[39m Union[_BoolLike_co, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger[Any]]\n\u001b[1;32m     15\u001b[0m _FloatLike_co \u001b[38;5;241m=\u001b[39m Union[_IntLike_co, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mfloating[Any]]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(\"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/trust_pdfs/(고객용) 상세상품설명서 20241025(비케이씨에스제오차).pdf\") as pdf:\n",
    "    # first_page = pdf.pages[0]\n",
    "    # print(first_page.chars[0])\n",
    "    # page_img = pdf_pages[0].to_image().original\n",
    "    im = pdf.pages[0].to_image(resolution=300)\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pdfplumber.utils import extract_text, get_bbox_overlap, obj_to_bbox\n",
    "import os\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    all_text = []\n",
    "\n",
    "    # Iterate over each page\n",
    "    for page in pdf.pages:\n",
    "        filtered_page = page  # current page\n",
    "        chars = filtered_page.chars  # captures all characters on the filtered_page\n",
    "    \n",
    "        # Iterate over each table found on the page\n",
    "        for table in page.find_tables():\n",
    "            first_table_char = page.crop(table.bbox).chars[0]  # stores the first character of the cropped table area\n",
    "            filtered_page = filtered_page.filter(lambda obj: \n",
    "                get_bbox_overlap(obj_to_bbox(obj), table.bbox) is None\n",
    "            )  # updated by filtering out characters that overlap with the table's bounding box\n",
    "            chars = filtered_page.chars\n",
    "\n",
    "            # Create a DataFrame from the extracted table data\n",
    "            df = pd.DataFrame(table.extract())\n",
    "            df.columns = df.iloc[0]  # first row set as the header\n",
    "            markdown = df.drop(0).to_markdown(index=False)  # rest converted to Markdown format\n",
    "            chars.append(first_table_char | {\"text\": markdown})  # Append the table markdown to the characters\n",
    "        \n",
    "        page_text = extract_text(chars, layout=True)  # Extracts the text from the filtered characters with layout preservation\n",
    "        all_text.append(page_text)\n",
    "    \n",
    "    pdf.close()\n",
    "    return \"\\n\".join(all_text)\n",
    "\n",
    "# Define input and output directories\n",
    "input_directory = \"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/trust_pdfs/\"\n",
    "output_directory = \"/Users/choihyelynn/Documents/GitHub/pdf-preprocessing/trust_txts/\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Process all PDF files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        extracted_text = process_pdf(file_path)\n",
    "\n",
    "        # Define output text file name\n",
    "        output_file = os.path.join(output_directory, filename.replace(\".pdf\", \".txt\"))\n",
    "\n",
    "        # Save the extracted text to a .txt file\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as text_file:\n",
    "            text_file.write(extracted_text)\n",
    "\n",
    "        print(f\"Processed and saved: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=doc.load_page(0)\n",
    "print(page.get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
